{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Machine Learning**  |  **Assignment-1** | Task-2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "STwNn638AiZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> a) Write a function in Python that takes two vectors as input (weight and feature vector) and\n",
        "returns the logistic regression prediction for that input."
      ],
      "metadata": {
        "id": "sZsYl4wMAfNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri1aSziCpxND",
        "outputId": "6ea795cf-a443-47bd-c9fe-ba70dabf6f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Prediction: 0.21416501695744133\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def logistic_regression_prediction(weight_vector, feature_vector):\n",
        "\n",
        "    if len(weight_vector) != len(feature_vector):\n",
        "        raise ValueError(\"Weight vector and feature vector must have the same length.\")\n",
        "\n",
        "    z = np.dot(weight_vector, feature_vector)\n",
        "\n",
        "    prediction = sigmoid(z)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "    weight_vector = np.array([0.5, -0.3, 0.8])\n",
        "feature_vector = np.array([1.0, 2.0, -1.5])\n",
        "\n",
        "prediction = logistic_regression_prediction(weight_vector, feature_vector)\n",
        "print(\"Logistic Regression Prediction:\", prediction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nUHh6EdVCJgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> b) Write a function in Python that takes a vector of predictions and a vector of actual values as\n",
        "input and returns the Logistic Loss."
      ],
      "metadata": {
        "id": "o_iH54hwBiUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def logistic_loss(predictions, actual_values):\n",
        "\n",
        "    if len(predictions) != len(actual_values):\n",
        "        raise ValueError(\"Prediction vector and actual values vector must have the same length.\")\n",
        "\n",
        "    epsilon = 1e-15\n",
        "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
        "\n",
        "    # logistic loss\n",
        "    loss = -np.mean(actual_values * np.log(predictions) + (1 - actual_values) * np.log(1 - predictions))\n",
        "\n",
        "    return loss\n",
        "\n",
        "predictions = np.array([0.5, -0.3, 0.8])\n",
        "actual_values = np.array([1.0, 2.0, -1.5])\n",
        "\n",
        "loss = logistic_loss(predictions, actual_values)\n",
        "print(\"Logistic Loss:\", loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trcAT0RKqAdT",
        "outputId": "7ab17cb0-ed45-4792-b9f4-1baf04a21133"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Loss: 24.48652647483175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AsLjPRvOxmgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> c) Write a function in Python that takes a vector of predictions and training data as input and\n",
        "returns the Gradient of Logistic Loss."
      ],
      "metadata": {
        "id": "rwU2SZ8kCooE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def logistic_loss_gradient(predictions, actual_values, feature_vector):\n",
        "\n",
        "    if len(predictions) != len(actual_values) or len(predictions) != len(feature_vector):\n",
        "        raise ValueError(\"Prediction vector, actual values vector, and feature vector must have the same length.\")\n",
        "\n",
        "\n",
        "    errors = predictions - actual_values\n",
        "\n",
        "    gradient = np.dot(errors, feature_vector)\n",
        "\n",
        "    return gradient\n",
        "\n",
        "predictions = np.array([0.5, -0.3, 0.8])\n",
        "actual_values = np.array([1.0, 2.0, -1.5])\n",
        "feature_vector = np.array([1.0, 2.0, -1.5])\n",
        "\n",
        "gradient = logistic_loss_gradient(predictions, actual_values, feature_vector)\n",
        "print(\"Gradient of Logistic Loss:\", gradient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obKTXYIYxl7v",
        "outputId": "f94206ad-0be9-4919-9204-9acba0c11819"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of Logistic Loss: -8.549999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9_aQTaGO21ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> d) Write a function in Python that implements the gradient descent algorithm for logistic\n",
        "regression. The function should take a weight vector, gradient of logistic loss and a stopping\n",
        "criterion as input and return the optimized weight vector."
      ],
      "metadata": {
        "id": "CxpebV_GCRU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def gradient_descent(weight_vector, gradient, learning_rate, stop_criterion):\n",
        "\n",
        "    if len(weight_vector) != len(gradient):\n",
        "        raise ValueError(\"Weight vector and gradient must have the same length.\")\n",
        "\n",
        "    iterations = 0\n",
        "\n",
        "    while not stop_criterion(weight_vector, iterations):\n",
        "        weight_vector -= learning_rate * gradient\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    return weight_vector, iterations\n",
        "\n",
        "\n",
        "weight_vector = np.array([0.5, -0.3, 0.8])\n",
        "gradient = np.array([0.1, -0.2, 0.3])\n",
        "learning_rate = 0.1\n",
        "\n",
        "def stop_criterion(weight_vector, iterations):\n",
        "    return iterations >= 100\n",
        "\n",
        "optimized_weight_vector, iterations = gradient_descent(weight_vector, gradient, learning_rate, stop_criterion)\n",
        "\n",
        "print(\"Optimized Weight Vector:\", optimized_weight_vector)\n",
        "print(\"Number of Iterations:\", iterations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj6oiefCyjwk",
        "outputId": "e8612310-4f72-44f6-a08b-7895377bde1e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Weight Vector: [-0.5  1.7 -2.2]\n",
            "Number of Iterations: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wjS06xIs_A-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> e) Use the functions created in the previous parts to apply logistic regression on the Iris Dataset.\n",
        "Use one vs rest approach to classify for each Iris flower species in the dataset."
      ],
      "metadata": {
        "id": "2ZZHF1UICcMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "zero_division=1\n",
        "\n",
        "def sigmoid(z):\n",
        "\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def gradient_of_logistic_loss(predictions, features, actual_values):\n",
        "\n",
        "\n",
        "    if len(predictions) != len(actual_values):\n",
        "        raise ValueError(\"Prediction vector and actual values vector must have the same length.\")\n",
        "\n",
        "    gradient = np.dot((predictions - actual_values), features) / len(predictions)\n",
        "\n",
        "    return gradient\n",
        "\n",
        "    # X: Input features , y: Target labels\n",
        "def train_one_vs_rest_classifier(class_label, X, y, learning_rate, stop_criterion):\n",
        "\n",
        "    binary_target = (y == class_label).astype(int)\n",
        "\n",
        "    weight_vector = np.zeros(X.shape[1])\n",
        "\n",
        "    iterations = 0\n",
        "\n",
        "    while not stop_criterion(weight_vector, iterations):\n",
        "\n",
        "        predictions = sigmoid(np.dot(X, weight_vector))\n",
        "        gradient = gradient_of_logistic_loss(predictions, X, binary_target)\n",
        "        weight_vector -= learning_rate * gradient\n",
        "        iterations += 1\n",
        "\n",
        "    return weight_vector\n",
        "\n",
        "def predict_one_vs_rest(classifiers, X):\n",
        "\n",
        "    predictions = np.zeros((X.shape[0], len(classifiers)), dtype=int)\n",
        "    for i, clf in enumerate(classifiers):\n",
        "        prob = sigmoid(np.dot(X, clf))\n",
        "        predictions[:, i] = prob > 0.5\n",
        "\n",
        "    return predictions.argmax(axis=1)\n",
        "\n",
        "# Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "learning_rate = 0.3\n",
        "\n",
        "classifiers = [train_one_vs_rest_classifier(class_label, X_train, y_train, learning_rate, stop_criterion) for class_label in range(3)]\n",
        "\n",
        "y_pred = predict_one_vs_rest(classifiers, X_test)\n",
        "y_pred_decoded = le.inverse_transform(y_pred)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_decoded)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_decoded, zero_division = 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jNeAQf5DiyB",
        "outputId": "2aea9070-60b0-417d-a986-08dc07e3a500"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.60\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95        10\n",
            "           1       0.42      0.89      0.57         9\n",
            "           2       1.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.60        30\n",
            "   macro avg       0.78      0.63      0.51        30\n",
            "weighted avg       0.80      0.60      0.49        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}